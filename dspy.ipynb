{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dsp.modules import GoogleVertexAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "from dsp.utils import dotdict\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from typing import List, Union, Optional\n",
    "import time\n",
    "import requests\n",
    "from google.oauth2 import service_account\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HF_API_TOKEN = os.environ.get(\"HF_API_TOKEN\")\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENVIRONMENT = os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "PINECONE_INDEX_NAME = \"basic-embeddings\"\n",
    "PINECONE_HOST = \"https://basic-embeddings-m8sj7l5.svc.aped-4627-b74a.pinecone.io\"\n",
    "VERTEX_MODEL_ID = \"gemini-1.5-flash-001\"\n",
    "VERTEX_PROJECT_ID = \"nvcc-dspy-rag\"\n",
    "VERTEX_REGION = \"us-central1\"\n",
    "VERTEX_CREDENTIALS = \"./vertex_credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads and caches the model\n",
    "def load_embedding_model(api_token: str = HF_API_TOKEN):\n",
    "    return SentenceTransformer(\"BAAI/bge-base-en-v1.5\", use_auth_token=api_token)\n",
    "\n",
    "\n",
    "def load_gemini_model(model_name: str = VERTEX_MODEL_ID,\n",
    "                      project: str = VERTEX_PROJECT_ID,\n",
    "                      location: str = VERTEX_REGION,\n",
    "                      credentials: str = VERTEX_CREDENTIALS):\n",
    "    credentials_obj = service_account.Credentials.from_service_account_file(credentials)\n",
    "    gemini_flash = GoogleVertexAI(\n",
    "        model_name=model_name,\n",
    "        project=project,\n",
    "        location=location,\n",
    "        credentials=credentials_obj\n",
    "    )\n",
    "    return gemini_flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PineconeRM(dspy.Retrieve):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pinecone_index_name: str = PINECONE_INDEX_NAME,\n",
    "        pinecone_api_key: str = PINECONE_API_KEY,\n",
    "        pinecone_env: Optional[str] = PINECONE_ENVIRONMENT,\n",
    "        k: int = 5\n",
    "    ):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__(k=k)\n",
    "        self._embedding_model = load_embedding_model()\n",
    "        self._pinecone_index = self._connect_pinecone_index()\n",
    "        \n",
    "        \n",
    "    def _init_pinecone(\n",
    "        self,\n",
    "        index_name: str = PINECONE_INDEX_NAME,\n",
    "        api_key: Optional[str] = PINECONE_API_KEY,\n",
    "        environment: Optional[str] = PINECONE_ENVIRONMENT,\n",
    "        host: str = PINECONE_HOST,\n",
    "        cloud: str = \"aws\",\n",
    "        region: str = \"us-east-1\",\n",
    "        dimension: Optional[int] = 768,\n",
    "        distance_metric: Optional[str] = \"cosine\",\n",
    "    ) -> pinecone.Index:\n",
    "        \"\"\"\n",
    "        Initialize pinecone and return the loaded index.\n",
    "\n",
    "        Args:\n",
    "            index_name (str): The name of the index to load. If the index is not does not exist, it will be created.\n",
    "            api_key (str, optional): The Pinecone API key, defaults to env var PINECONE_API_KEY if not provided.\n",
    "            environment (str, optional): The environment (ie. `us-west1-gcp` or `gcp-starter`). Defaults to PINECONE_ENVIRONMENT.\n",
    "\n",
    "        Returns:\n",
    "            pinecone.Index: The loaded index.\n",
    "        \"\"\"\n",
    "        \n",
    "        pc = Pinecone(api_key=api_key)\n",
    "        \n",
    "        pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=dimension,\n",
    "                metric=distance_metric,\n",
    "                spec=ServerlessSpec(\n",
    "                  cloud=cloud,\n",
    "                  region=region\n",
    "                ),\n",
    "                deletion_protection=\"disabled\"\n",
    "            )\n",
    "        index = pc.Index(index_name, host=host)\n",
    "\n",
    "        return index\n",
    "    \n",
    "    def _connect_pinecone_index(\n",
    "        index_name: str = PINECONE_INDEX_NAME,\n",
    "        api_key: str = PINECONE_API_KEY,\n",
    "        host: str = PINECONE_HOST,\n",
    "        environment: Optional[str] = PINECONE_ENVIRONMENT\n",
    "    ) -> pinecone.Index:\n",
    "        \"\"\"\n",
    "        Creates a connection to a existing pinecone index and returns the index\n",
    "        \"\"\"\n",
    "        pc = Pinecone(api_key=api_key)\n",
    "        index = pc.Index(index_name, host=host)\n",
    "    \n",
    "        return index\n",
    "    \n",
    "    def _get_embedding(\n",
    "        self, \n",
    "        query: str,\n",
    "    ) -> List[float]:\n",
    "        \"\"\"\n",
    "        Return query vector after creating embedding using HuggingFace BAAI/bge-base-en-v1.5\n",
    "\n",
    "        Args:\n",
    "            queries (list): Query string to embed.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: Embedding corresponding to each query.\n",
    "        \"\"\"\n",
    "        embedding = list(self._embedding_model.encode(str(query), convert_to_numpy=True))\n",
    "        \n",
    "        return embedding\n",
    "\n",
    "\n",
    "    def forward(self, query: str, k: Optional[int]) -> dspy.Prediction:\n",
    "        \"\"\"\n",
    "        Search with pinecone for top self.k passages most similar to the input query\n",
    "\n",
    "        Args:\n",
    "            query (str): The query string we are receiving similar results for\n",
    "\n",
    "        Returns:\n",
    "            dspy.Prediction: An object containing the retrieved passages.\n",
    "        \"\"\"\n",
    "        embeddings = self._get_embedding(query)\n",
    "\n",
    "        results_dict = self._pinecone_index.query(\n",
    "            vector = embeddings,\n",
    "            top_k = k,\n",
    "            include_metadata = True\n",
    "        )\n",
    "        \n",
    "        sorted_results = sorted(\n",
    "            results_dict[\"matches\"],\n",
    "            key=lambda x: x.get(\"scores\", 0.0),\n",
    "            reverse=True,\n",
    "        )\n",
    "        passages = [result[\"metadata\"][\"text\"] for result in sorted_results]\n",
    "        passages = [dotdict({\"long_text\": passage}) for passage in passages]\n",
    "        return dspy.Prediction(passages=passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash = load_gemini_model()\n",
    "pinecone_retriever = PineconeRM\n",
    "dspy.settings.configure(lm=gemini_flash, rm=pinecone_retriever)\n",
    "\n",
    "\n",
    "class GenerateAnswerWithContext(dspy.Signature):\n",
    "    \"\"\"Answer the question based on the context and query provided, and on the scale of 10 tell how confident you are about the answer.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts to consider\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"answer from context\")\n",
    "\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=5):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k = num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswerWithContext)\n",
    "    \n",
    "    def forward(self, query):\n",
    "        context = self.retrieve(query).passages\n",
    "        prediction = self.generate_answer(context=context, question=query)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/polydeltaintern/anaconda3/envs/simple-nova-rag/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:174: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v3 of SentenceTransformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PineconeRM' object has no attribute 'long_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rag \u001b[38;5;241m=\u001b[39m RAG()\n\u001b[1;32m      2\u001b[0m txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the core values at NOVA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtxt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39manswer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(ans)\n",
      "File \u001b[0;32m~/anaconda3/envs/simple-nova-rag/lib/python3.12/site-packages/dspy/primitives/program.py:26\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m, in \u001b[0;36mRAG.forward\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, query):\n\u001b[0;32m---> 21\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpassages\n\u001b[1;32m     22\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_answer(context\u001b[38;5;241m=\u001b[39mcontext, question\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dspy\u001b[38;5;241m.\u001b[39mPrediction(context\u001b[38;5;241m=\u001b[39mcontext, answer\u001b[38;5;241m=\u001b[39mprediction\u001b[38;5;241m.\u001b[39manswer)\n",
      "File \u001b[0;32m~/anaconda3/envs/simple-nova-rag/lib/python3.12/site-packages/dspy/retrieve/retrieve.py:40\u001b[0m, in \u001b[0;36mRetrieve.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simple-nova-rag/lib/python3.12/site-packages/dspy/retrieve/retrieve.py:69\u001b[0m, in \u001b[0;36mRetrieve.forward\u001b[0;34m(self, query_or_queries, k, by_prob, with_metadata, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m with_metadata:\n\u001b[0;32m---> 69\u001b[0m     passages \u001b[38;5;241m=\u001b[39m \u001b[43mdsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieveEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(passages\u001b[38;5;241m=\u001b[39mpassages)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/simple-nova-rag/lib/python3.12/site-packages/dsp/primitives/search.py:93\u001b[0m, in \u001b[0;36mretrieveEnsemble\u001b[0;34m(queries, k, by_prob, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m queries \u001b[38;5;241m=\u001b[39m [q \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries \u001b[38;5;28;01mif\u001b[39;00m q]\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queries) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m passages \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries:\n",
      "File \u001b[0;32m~/anaconda3/envs/simple-nova-rag/lib/python3.12/site-packages/dsp/primitives/search.py:19\u001b[0m, in \u001b[0;36mretrieve\u001b[0;34m(query, k, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(passages, Iterable):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# it's not an iterable yet; make it one.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# TODO: we should unify the type signatures of dspy.Retriever\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     passages \u001b[38;5;241m=\u001b[39m [passages]\n\u001b[0;32m---> 19\u001b[0m passages \u001b[38;5;241m=\u001b[39m [\u001b[43mpsg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong_text\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m psg \u001b[38;5;129;01min\u001b[39;00m passages]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mreranker:\n\u001b[1;32m     22\u001b[0m     passages_cs_scores \u001b[38;5;241m=\u001b[39m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mreranker(query, passages)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PineconeRM' object has no attribute 'long_text'"
     ]
    }
   ],
   "source": [
    "rag = RAG()\n",
    "txt = \"What are the core values at NOVA\"\n",
    "ans = rag(query=txt).answer\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-nova-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
